{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac230c2",
   "metadata": {},
   "source": [
    "You have two DataFrames:\n",
    "df_sales: sale_id, product_id, sale_date, amount\n",
    "df_products: product_id, product_name, category\n",
    "Write PySpark code to:\n",
    "\n",
    "Join the two DataFrames on product_id\n",
    "Filter for sales from the last 30 days (assume today's date using current_date())\n",
    "Calculate the total sales amount per category\n",
    "Find the top 3 categories by total sales\n",
    "Include a column showing each category's percentage of total sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType\n",
    "from pyspark.sql.functions import col, date_sub, broadcast, current_date, round, sum as agg_sum, lit\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"practice_questions\").getOrCreate()\n",
    "\n",
    "sales_schema = StructType([\n",
    "    StructField(\"sale_id\", StringType()),\n",
    "    StructField(\"product_id\", StringType()),\n",
    "    StructField(\"sale_date\", DateType()),\n",
    "    StructField(\"amount\", FloatType())\n",
    "])\n",
    "\n",
    "products_schema = StructType([\n",
    "    StructField(\"product_id\", StringType()),\n",
    "    StructField(\"product_name\", StringType()),\n",
    "    StructField(\"category\", StringType())\n",
    "])\n",
    "\n",
    "sales_df = spark.read.format(\"csv\").schema(sales_schema).option(\"header\", \"True\").load(\"dfbs:/raw/data/sales.csv\")\n",
    "products_df = spark.read.format(\"parquet\").schema(products_df).load(\"dbfs:/raw/data/products.parquet\")\n",
    "\n",
    "sales_df = sales_df.filter(col(\"sale_date\") < date_sub(current_date(), -30)) # filter early for predicate pushdown\n",
    "joined_df = sales_df.join(broadcast(products_df), \"product_id\", \"inner\")\n",
    "joined_df = joined_df.select(\"category\", \"amount\") # predicate pushdown\n",
    "\n",
    "joined_df = joined_df.groupBy(\"category\").agg(agg_sum(\"amount\").alias(\"total_sales\"))\n",
    "total_sale_sum = joined_df.agg(agg_sum(\"total_sales\")).collect()[0][0]\n",
    "window_spec = Window.orderBy(col(\"total_sales\").desc())\n",
    "\n",
    "\n",
    "ranked_df = joined_df.withColumn(\"percentage_sum\", round(col(\"total_sales\") * 100 / lit(total_sale_sum) , 2))\n",
    "ranked_df = joined_df.dense_rank().over(window_spec).alias(\"category_rank\")\n",
    "top_df = ranked_df.filter(col(\"category_rank\") <= 3)\n",
    "top_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c885bd4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
